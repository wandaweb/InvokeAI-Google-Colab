{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Invoke AI Notebook\n",
        "\n",
        "Works: Generating images with the SDXL base model and refiner.\n",
        "\n",
        "Does not work: Adding custom checkpoints."
      ],
      "metadata": {
        "id": "D4TNDJdRpPN9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIhVvU8jkdm6"
      },
      "outputs": [],
      "source": [
        "#@markdown This step usually takes about 5 minutes.\n",
        "import os\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "if useGoogleDrive:\n",
        "  drive.mount('/content/drive')\n",
        "  if not googleDriveModelsFolder.startswith('/'):\n",
        "    googleDriveModelsFolder = '/' + googleDriveModelsFolder\n",
        "  modelsPath = \"/content/drive/MyDrive\"+googleDriveModelsFolder\n",
        "  if not modelsPath.endswith(\"/\"):\n",
        "   modelsPath = modelsPath + \"/\"\n",
        "\n",
        "env = os.environ.copy()\n",
        "\n",
        "!pip install 'InvokeAI[xformers]' --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTkFxvuH0BsX"
      },
      "outputs": [],
      "source": [
        "#@markdown # Downloading Models\n",
        "\n",
        "!mkdir /content/invokeai\n",
        "!mkdir /content/invokeai/configs\n",
        "\n",
        "#@markdown Download only the default model in initial configuration.\n",
        "#@markdown Checking this prevents running out of space in Colab.\n",
        "\n",
        "defaultOnly = True #@param {type:\"boolean\"}\n",
        "skipWeights = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown This step usually takes about 2 minutes with only the default model and no weights.\n",
        "\n",
        "#@markdown You can ignore \"File exists\" warnings in the output.\n",
        "\n",
        "cmd = 'invokeai-configure --root_dir /content/invokeai --yes'\n",
        "\n",
        "if defaultOnly:\n",
        "  cmd += ' --default_only'\n",
        "\n",
        "if skipWeights:\n",
        "  cmd += ' --skip-sd-weights'\n",
        "\n",
        "subprocess.run(cmd, shell=True, env=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgoAu7NF8etg"
      },
      "outputs": [],
      "source": [
        "#@markdown Adding the SDXL Base Model\n",
        "\n",
        "#@markdown Installing SDXL base took about 20 minutes initially, but it's finished instantly\n",
        "#@markdown in subsequent runs if Google Drive is enabled. You can execute the first run in a runtime\n",
        "#@markdown without a GPU to save the model to Google Drive without spending GPU time.\n",
        "\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "# Install the SDXL base model\n",
        "def installSdxl(env):\n",
        "  installCmd = 'invokeai-model-install --add \"stabilityai/stable-diffusion-xl-base-1.0\" --root_dir /content/invokeai'\n",
        "  subprocess.run(installCmd, shell=True, env=env)\n",
        "\n",
        "sdxlBaseSubfolderName = '/stable-diffusion-xl-base-1-0'\n",
        "\n",
        "if useGoogleDrive:\n",
        "  alreadyInstalled = True\n",
        "\n",
        "  driveSdxlMainFolder = modelsPath + \"sdxl/main\"\n",
        "  if not path.exists(driveSdxlMainFolder):\n",
        "    os.makedirs(driveSdxlMainFolder, exist_ok=True)\n",
        "    alreadyInstalled = False\n",
        "\n",
        "  localModelsSdxlFolder = \"/content/invokeai/models/sdxl/\"\n",
        "  localSdxlMainFolder = localModelsSdxlFolder + \"main\"\n",
        "\n",
        "  subprocess.run('rm -rf ' + localModelsSdxlFolder, shell=True, env=env)\n",
        "  subprocess.run('rmdir ' + localModelsSdxlFolder, shell=True, env=env)\n",
        "\n",
        "  if not alreadyInstalled:\n",
        "    if not path.exists(localModelsSdxlFolder):\n",
        "      os.makedirs(localModelsSdxlFolder, exist_ok=True)\n",
        "    subprocess.run('ln -s '+driveSdxlMainFolder+' '+localModelsSdxlFolder, shell=True, env=env)\n",
        "    installSdxl(env)\n",
        "  else:\n",
        "    if not path.exists(localSdxlMainFolder):\n",
        "      os.makedirs(localSdxlMainFolder, exist_ok=True)\n",
        "    subprocess.run('ln -s '+driveSdxlMainFolder + sdxlBaseSubfolderName+' '+ localSdxlMainFolder, shell=True, env=env)\n",
        "    updateModelsYaml = True\n",
        "    with open('/content/invokeai/configs/models.yaml') as f:\n",
        "      if 'stable-diffusion-xl-base-1-0' in f.read():\n",
        "        updateModelsYaml = False\n",
        "    if updateModelsYaml:\n",
        "      with open('/content/invokeai/configs/models.yaml', 'a') as file:\n",
        "        lines = [\n",
        "          'sdxl/main/stable-diffusion-xl-base-1-0:\\n',\n",
        "          '  path: sdxl/main/stable-diffusion-xl-base-1-0\\n',\n",
        "          '  description: Stable Diffusion XL base model (12 GB)\\n',\n",
        "          '  variant: normal\\n',\n",
        "          '  format: diffusers\\n'\n",
        "        ]\n",
        "        file.writelines(lines)\n",
        "else:\n",
        "  installSdxl(env)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Adding the refiner and vae. This one took about 14 minutes.\n",
        "#@markdown Skip this step if you don't need these models.\n",
        "!invokeai-model-install --add \"stabilityai/stable-diffusion-xl-refiner-1.0\" --root_dir /content/invokeai --yes\n",
        "!invokeai-model-install --add \"madebyollin/sdxl-vae-fp16-fix\" --root_dir /content/invokeai --yes"
      ],
      "metadata": {
        "id": "aHKM_DyQirz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN-IExD5XwOs"
      },
      "outputs": [],
      "source": [
        "#@markdown # Starting the Web UI\n",
        "\n",
        "%cd /content/invokeai/\n",
        "!npm install -g localtunnel\n",
        "\n",
        "#@markdown Copy the IP address shown in the output above the line\n",
        "#@markdown \"your url is: https://some-random-words.loca.lt\"\n",
        "!wget -q -O - ipv4.icanhazip.com\n",
        "\n",
        "#@markdown Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\"\n",
        "\n",
        "#@markdown Click the localtunnel url and paste the IP you copied earlier to the \"Endpoint IP\" text field\n",
        "!lt --port 9090 --local_https False & invokeai-web  --root /content/invokeai/\n",
        "\n",
        "#@markdown If the UI shows a red dot that says 'disconnected' when hovered in the upper\n",
        "#@markdown right corner and the Invoke button is disabled, change 'https' to 'http'\n",
        "#@markdown in the browser's address bar and press enter.\n",
        "#@markdown When the page reloads, the UI should work properly.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
