{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Invoke AI Notebook\n",
        "\n",
        "Works on the free tier: Generating images with the SDXL base model and refiner. Adding SDXL models in diffusers format from HuggingFace.\n",
        "\n",
        "Works, but only with Colab Pro: Adding custom checkpoints and LoRAs."
      ],
      "metadata": {
        "id": "D4TNDJdRpPN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1"
      ],
      "metadata": {
        "id": "Ow5L4LUnr_Cs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIhVvU8jkdm6"
      },
      "outputs": [],
      "source": [
        "#@markdown # Installing InvokeAI\n",
        "\n",
        "#@markdown Use Google Drive to store models (uses about 7 GB). Uncheck this if you don't have enough space in your Drive.\n",
        "useGoogleDrive = True #@param {type:\"boolean\"}\n",
        "\n",
        "googleDriveModelsFolder = '/stablemodels' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown This step usually takes about 5 minutes.\n",
        "\n",
        "# @markdown You can ignore the message about restarting the runtime. Additionally, warnings about incompatible packages can be ignored as well.\n",
        "import os\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "if useGoogleDrive:\n",
        "  drive.mount('/content/drive')\n",
        "  if not googleDriveModelsFolder.startswith('/'):\n",
        "    googleDriveModelsFolder = '/' + googleDriveModelsFolder\n",
        "  modelsPath = \"/content/drive/MyDrive\"+googleDriveModelsFolder\n",
        "  if not modelsPath.endswith(\"/\"):\n",
        "   modelsPath = modelsPath + \"/\"\n",
        "\n",
        "env = os.environ.copy()\n",
        "\n",
        "!pip install 'InvokeAI[xformers]' --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "# Replace with this line to install a version that uses less RAM and won't crash\n",
        "#!pip install 'InvokeAI[xformers]==3.1.1' --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2"
      ],
      "metadata": {
        "id": "ERca0J67r8Ss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTkFxvuH0BsX"
      },
      "outputs": [],
      "source": [
        "#@markdown # Configuration and downloading default models\n",
        "\n",
        "!mkdir /content/invokeai\n",
        "!mkdir /content/invokeai/configs\n",
        "\n",
        "#@markdown Download only the default model in initial configuration.\n",
        "#@markdown Checking this prevents running out of space in Colab.\n",
        "\n",
        "defaultOnly = True #@param {type:\"boolean\"}\n",
        "skipWeights = True #@param {type:\"boolean\"}\n",
        "noFullPrecision = True  #@param {type:\"boolean\"}\n",
        "#@markdown This step usually takes about 2 minutes with only the default model and no weights.\n",
        "\n",
        "#@markdown You can ignore \"File exists\" warnings in the output.\n",
        "\n",
        "cmd = 'invokeai-configure --root_dir /content/invokeai --yes'\n",
        "\n",
        "if defaultOnly:\n",
        "  cmd += ' --default_only'\n",
        "\n",
        "if skipWeights:\n",
        "  cmd += ' --skip-sd-weights'\n",
        "\n",
        "if noFullPrecision:\n",
        "  cmd += ' --no-full-precision'\n",
        "\n",
        "get_ipython().system(cmd)\n",
        "\n",
        "import fileinput\n",
        "import os\n",
        "def find(name, path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if name in files:\n",
        "            return os.path.join(root, name)\n",
        "\n",
        "if noFullPrecision:\n",
        "  model_install_file = find('model_install_backend.py', '/usr/local/lib')\n",
        "  print('modifying file ' + model_install_file)\n",
        "  for line in fileinput.input(model_install_file, inplace=True):\n",
        "    if ('precision = torch_dtype(choose_torch_device())' in line):\n",
        "       line = line.replace('torch_dtype(choose_torch_device())', 'torch.float16')\n",
        "    print(line, end='')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 - Adding the SDXL Base Model - Optional, but at least one model is required"
      ],
      "metadata": {
        "id": "LHerfGJjsAya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgoAu7NF8etg"
      },
      "outputs": [],
      "source": [
        "#@markdown # Adding the SDXL Base Model\n",
        "\n",
        "#@markdown Installing SDXL base took about 10 minutes initially, but it's finished instantly\n",
        "#@markdown in subsequent runs if Google Drive is enabled. You can execute the first run in a runtime\n",
        "#@markdown without a GPU to save the model to Google Drive without spending GPU time.\n",
        "\n",
        "#@markdown This will delete anything in the folder /content/invokeai/models/sdxl\n",
        "\n",
        "import os.path\n",
        "from os import path\n",
        "\n",
        "# Install the SDXL base model\n",
        "def installSdxl():\n",
        "  installCmd = 'invokeai-model-install --add \"stabilityai/stable-diffusion-xl-base-1.0\" --root_dir /content/invokeai'\n",
        "  get_ipython().system(installCmd)\n",
        "\n",
        "sdxlBaseSubfolderName = '/stable-diffusion-xl-base-1-0'\n",
        "\n",
        "if useGoogleDrive:\n",
        "  alreadyInstalled = True\n",
        "\n",
        "  driveSdxlMainFolder = modelsPath + 'sdxl/main'\n",
        "  if not path.exists(driveSdxlMainFolder):\n",
        "    os.makedirs(driveSdxlMainFolder, exist_ok=True)\n",
        "    alreadyInstalled = False\n",
        "\n",
        "  localModelsSdxlFolder = '/content/invokeai/models/sdxl/'\n",
        "  localSdxlMainFolder = localModelsSdxlFolder + 'main'\n",
        "\n",
        "  get_ipython().system('rm -rf ' + localModelsSdxlFolder)\n",
        "  get_ipython().system('rmdir ' + localModelsSdxlFolder)\n",
        "\n",
        "  if not alreadyInstalled:\n",
        "    if not path.exists(localModelsSdxlFolder):\n",
        "      os.makedirs(localModelsSdxlFolder, exist_ok=True)\n",
        "    get_ipython().system('ln -s '+driveSdxlMainFolder+' '+localModelsSdxlFolder)\n",
        "    installSdxl()\n",
        "    get_ipython().system('unlink '+localSdxlMainFolder)\n",
        "    if not path.exists(localSdxlMainFolder):\n",
        "      os.makedirs(localSdxlMainFolder, exist_ok=True)\n",
        "    get_ipython().system('ln -s '+driveSdxlMainFolder + sdxlBaseSubfolderName+' '+ localSdxlMainFolder+ sdxlBaseSubfolderName)\n",
        "  else:\n",
        "    if not path.exists(localSdxlMainFolder):\n",
        "      os.makedirs(localSdxlMainFolder, exist_ok=True)\n",
        "    get_ipython().system('ln -s '+driveSdxlMainFolder + sdxlBaseSubfolderName+' '+ localSdxlMainFolder+ sdxlBaseSubfolderName)\n",
        "    updateModelsYaml = True\n",
        "    with open('/content/invokeai/configs/models.yaml') as f:\n",
        "      if 'stable-diffusion-xl-base-1-0' in f.read():\n",
        "        updateModelsYaml = False\n",
        "    if updateModelsYaml:\n",
        "      with open('/content/invokeai/configs/models.yaml', 'a') as file:\n",
        "        lines = [\n",
        "          'sdxl/main/stable-diffusion-xl-base-1-0:\\n',\n",
        "          '  path: sdxl/main/stable-diffusion-xl-base-1-0\\n',\n",
        "          '  description: Stable Diffusion XL base model (12 GB)\\n',\n",
        "          '  variant: normal\\n',\n",
        "          '  format: diffusers\\n'\n",
        "        ]\n",
        "        file.writelines(lines)\n",
        "else:\n",
        "  installSdxl()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Download the refiner model and vae - Optional"
      ],
      "metadata": {
        "id": "3ahYWcmrsKIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Adding the refiner and vae. This one took about 14 minutes.\n",
        "#@markdown Skip this step if you don't need these models.\n",
        "!invokeai-model-install --add \"stabilityai/stable-diffusion-xl-refiner-1.0\" --root_dir /content/invokeai --yes\n",
        "!invokeai-model-install --add \"madebyollin/sdxl-vae-fp16-fix\" --root_dir /content/invokeai --yes"
      ],
      "metadata": {
        "id": "aHKM_DyQirz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Saving outputs to a Drive folder - Optional"
      ],
      "metadata": {
        "id": "a2M0-QnjsPqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linking output images to Google Drive\n",
        "outputDrivePath = '/content/drive/MyDrive/images/invoke-outputs' #@param {type:\"string\"}\n",
        "# Full path to the output folder on Google Drive\n",
        "\n",
        "saveDatabase = True #@param {type:\"boolean\"}\n",
        "from os import path\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from os import path\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if not outputDrivePath.endswith('/'):\n",
        "  outputDrivePath = outputDrivePath + '/'\n",
        "imagesDrivePath = outputDrivePath + 'images'\n",
        "databaseDrivePath = outputDrivePath + 'databases'\n",
        "if not path.exists(imagesDrivePath):\n",
        "  os.makedirs(imagesDrivePath, exist_ok=True)\n",
        "\n",
        "\n",
        "outputsLocalPath = '/content/invokeai/outputs'\n",
        "imagesLocalPath = '/content/invokeai/outputs/images'\n",
        "\n",
        "if not path.exists(outputsLocalPath):\n",
        "  os.makedirs(outputsLocalPath, exist_ok=True)\n",
        "\n",
        "import datetime\n",
        "\n",
        "if path.exists(imagesLocalPath):\n",
        "    cmd = f'mv {imagesLocalPath} {imagesLocalPath}-backup{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
        "    get_ipython().system(cmd)\n",
        "\n",
        "cmd = f'ln -s {imagesDrivePath} {outputsLocalPath}'\n",
        "get_ipython().system(cmd)\n",
        "\n",
        "# Linking the database\n",
        "if saveDatabase:\n",
        "  if not path.exists(databaseDrivePath):\n",
        "    os.makedirs(databaseDrivePath, exist_ok=True)\n",
        "\n",
        "  databaseLocalPath = '/content/invokeai/databases'\n",
        "\n",
        "  cmd = f'mv {databaseLocalPath} {databaseLocalPath}-backup{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
        "  get_ipython().system(cmd)\n",
        "\n",
        "  cmd = f'ln -s {databaseDrivePath} /content/invokeai'\n",
        "  get_ipython().system(cmd)\n"
      ],
      "metadata": {
        "id": "3owdtpnWsRoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Load any SDXL models in diffusers format from Drive - Optional"
      ],
      "metadata": {
        "id": "jS0EJ4LosUFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding custom SDXL models in diffusers format from Goole Drive\n",
        "googleDriveModelFolder = '/content/drive/MyDrive/path-to-the-model' #@param {type:\"string\"}\n",
        "#@markdown - Full path to the model folder on Google Drive\n",
        "\n",
        "#@markdown This can also be done from the Model Manager in the Web UI.\n",
        "\n",
        "updateModelsYaml = True\n",
        "with open('/content/invokeai/configs/models.yaml') as f:\n",
        "      if googleDriveModelFolder in f.read():\n",
        "        updateModelsYaml = False\n",
        "if updateModelsYaml:\n",
        "      with open('/content/invokeai/configs/models.yaml', 'a') as file:\n",
        "        folders = googleDriveModelFolder.split('/');\n",
        "        modelname = folders[len(folders)-1]\n",
        "        print(modelname)\n",
        "        lines = [\n",
        "          'sdxl/main/' + modelname + ':\\n',\n",
        "          '  path: ' + googleDriveModelFolder + '\\n',\n",
        "          '  description: Stable Diffusion XL base model (12 GB)\\n',\n",
        "          '  variant: normal\\n',\n",
        "          '  format: diffusers\\n'\n",
        "        ]\n",
        "        file.writelines(lines)"
      ],
      "metadata": {
        "id": "sdaNxzYPsaXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Starting the app"
      ],
      "metadata": {
        "id": "T4xrUy3Gsomd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Option 1: Starting the Web UI with ngrok\n",
        "!pip install pyngrok\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "import fileinput\n",
        "import sys\n",
        "\n",
        "Ngrok_token = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add ngrok token (obtainable from https://ngrok.com)\n",
        "\n",
        "#@markdown Only works with InvokeAI 3.0.2 and later\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(9090 , pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token),\n",
        "                    bind_tls=True).public_url\n",
        "  print(srv)\n",
        "  get_ipython().system(\"invokeai-web  --root /content/invokeai/\")\n",
        "else:\n",
        "  print('An ngrok token is required. You can get one on https://ngrok.com and paste it into the ngrok_token field.')"
      ],
      "metadata": {
        "id": "8P-UgO8Ysrlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Option 2: Starting the Web UI with RemoteMoe\n",
        "\n",
        "#@markdown Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\"\n",
        "#@markdown and click on the link that ends with .remote.moe\n",
        "\n",
        "!mkdir  ~/.ssh/\n",
        "!touch  ~/.ssh/known_hosts\n",
        "!ssh-keyscan -t rsa remote.moe >> ~/.ssh/known_hosts\n",
        "!rm /root/.ssh/id_rsa\n",
        "!ssh-keygen -t rsa -b 4096 -f /root/.ssh/id_rsa -q -N \"\"\n",
        "!invokeai-web  --root /content/invokeai/ & ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /root/.ssh/id_rsa remote.moe"
      ],
      "metadata": {
        "id": "uH3i_lv3690K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN-IExD5XwOs"
      },
      "outputs": [],
      "source": [
        "#@markdown # Option 3: Starting the Web UI with Localtunnel\n",
        "\n",
        "%cd /content/invokeai/\n",
        "!npm install -g localtunnel\n",
        "\n",
        "# @markdown **Warning: Localtown has been down recently. If the localtunnel link does not show up in the output, go with the ngrok option.**\n",
        "# @markdown\n",
        "# @markdown Copy the IP address shown in the output above the line\n",
        "# @markdown \"your url is: https://some-random-words.loca.lt\"\n",
        "!wget -q -O - ipv4.icanhazip.com\n",
        "\n",
        "#@markdown Wait for the line that says \"Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\"\n",
        "\n",
        "#@markdown Click the localtunnel url and paste the IP you copied earlier to the \"Endpoint IP\" text field\n",
        "!lt --port 9090 --local_https False & invokeai-web  --root /content/invokeai/\n",
        "\n",
        "#@markdown If the UI shows a red dot that says 'disconnected' when hovered in the upper\n",
        "#@markdown right corner and the Invoke button is disabled, change 'https' to 'http'\n",
        "#@markdown in the browser's address bar and press enter.\n",
        "#@markdown When the page reloads, the UI should work properly.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
